title: "Span Boundary Detection"
description: "This spaCy project presents a new experimental suggester that tries to learn span boundaries to produce more precise candidate spans."
# Variables can be referenced across the project.yml using ${vars.var_name}
vars:
  config: "config_tok2vec" # config_tok2vec, config_trf

  dataset: "toxic" # healthsea, toxic, genia
  suggester: "sbd" # ngram, sbd

  train: "train"
  dev: "dev"
  span_key: "sc"

  models:
    model_sbd: "training/sbd/${vars.dataset}/${vars.config}/model-best"
    model_spancat: "training/spancat/${vars.dataset}/${vars.config}_${vars.suggester}/model-best"

  gpu_id: 0
  eval_split: 0.25

# These are the directories that the project needs. The project CLI will make
# sure that they always exist.
directories: ["assets", "training", "configs", "scripts", "data", "metrics"]

# Assets that should be downloaded or available in the directory. We're shipping
# them with the project, so they won't have to be downloaded. But the
# 'project assets' command still lets you verify that all required files are available.
assets:
  - dest: "assets/healthsea_ner.jsonl"
    description: "NER annotations exported from Prodigy with 5000 examples and 2 labels"
    url: https://github.com/explosion/healthsea/blob/main/project/assets/ner/annotation.jsonl

  - dest: "assets/toxic_spans_annotations.csv"
    description: "Annotations from the ToxicSpans dataset"
    url: https://github.com/ipavlopoulos/toxic_spans/tree/master/data/annotations.csv

  - dest: "assets/toxic_spans.csv"
    description: "Spans from the ToxicSpans dataset"
    url: https://github.com/ipavlopoulos/toxic_spans/tree/master/data/spans.csv

  - dest: "assets/toxic_spans_comments.csv"
    description: "Comments from the ToxicSpans dataset"
    url: https://github.com/ipavlopoulos/toxic_spans/tree/master/data/comments.csv

  - dest: "assets/genia_train.iob"
    description: "Genia dataset"
    url: "https://github.com/thecharm/boundary-aware-nested-ner/tree/master/Our_boundary-aware_model/data/genia/genia.train.iob2"

  - dest: "assets/genia_dev.iob"
    description: "Genia dataset"
    url: "https://github.com/thecharm/boundary-aware-nested-ner/tree/master/Our_boundary-aware_model/data/genia/genia.dev.iob2"

# Workflows are sequences of commands (see below) executed in order. You can
# run them via "spacy project run [workflow]". If a commands's inputs/outputs
# haven't changed, it won't be re-run.
workflows:
  preprocess:
    - preprocess_healthsea
    - preprocess_toxic
    - preprocess_genia
  analyze:
    - analyze_healthsea
    - analyze_healthsea
    - analyze_healthsea
  train:
    - train_sbd
    - evaluate_sbd
    - train_spancat
    - evaluate_spancat
    - evaluate_suggester
# Project commands, specified in a style similar to CI config files (e.g. Azure
# pipelines). The name is the command name that lets you trigger the command
# via "spacy project run [command] [path]". The help message is optional and
# shown when executing "spacy project run [optional command] [path] --help".
commands:
  - name: "preprocess_healthsea"
    help: "Format Healthsea annotations into .spaCy training format"
    script:
      - "python scripts/preprocessing/preprocess_healthsea.py assets/healthsea_ner.jsonl data/healthsea_${vars.train}.spacy data/healthsea_${vars.dev}.spacy ${vars.eval_split} ${vars.span_key}"
    deps:
      - "assets/healthsea_ner.jsonl"
      - "scripts/preprocessing/preprocess_healthsea.py"
    outputs:
      - "data/healthsea_${vars.train}.spacy"
      - "data/healthsea_${vars.dev}.spacy"

  - name: "preprocess_genia"
    help: "Format Genia annotations into .spaCy training format"
    script:
      - "python scripts/preprocessing/preprocess_genia.py assets/genia_train.iob assets/genia_dev.iob data/genia_${vars.train}.spacy data/genia_${vars.dev}.spacy"
    deps:
      - "assets/genia_train.iob"
      - "assets/genia_dev.iob"
    outputs:
      - "data/genia_${vars.train}.spacy"
      - "data/genia_${vars.dev}.spacy"

  - name: "preprocess_toxic"
    help: "Format annotations into .spaCy training format"
    script:
      - "python scripts/preprocessing/preprocess_toxic.py assets/toxic_spans.csv assets/toxic_spans_annotations.csv assets/toxic_spans_comments.csv data/toxic_${vars.train}.spacy data/toxic_${vars.dev}.spacy ${vars.eval_split} ${vars.span_key}"
    deps:
      - "assets/toxic_spans.csv"
      - "assets/toxic_spans_annotations.csv"
      - "assets/toxic_spans_comments.csv"
      - "scripts/preprocessing/preprocess_toxic.py"
    outputs:
      - "data/toxic_${vars.train}.spacy"
      - "data/toxic_${vars.dev}.spacy"

  # Required to have spacy-span-analyzer installed (https://github.com/ljvmiranda921/spacy-span-analyzer)
  - name: "analyze_healthsea"
    help: "Analyze Healthsea training dataset"
    script:
      - "spacy-span-analyzer data/healthsea_${vars.train}.spacy"
    deps:
      - "data/healthsea_${vars.train}.spacy"

  - name: "analyze_toxic"
    help: "Analyze ToxicSpans training dataset"
    script:
      - "spacy-span-analyzer data/toxic_${vars.train}.spacy"
    deps:
      - "data/toxic_${vars.train}.spacy"

  - name: "analyze_genia"
    help: "Analyze Genia training dataset"
    script:
      - "spacy-span-analyzer data/genia_${vars.train}.spacy"
    deps:
      - "data/genia_${vars.train}.spacy"
  # ----------------------------------------------------------------------------------------------------

  - name: "train_sbd"
    help: "Train SpanBoundaryDetection model"
    script:
      - "python -m spacy train configs/sbd/${vars.dataset}/${vars.config}.cfg --output training/sbd/${vars.dataset}/${vars.config}/ --paths.train data/${vars.dataset}_${vars.train}.spacy --paths.dev data/${vars.dataset}_${vars.dev}.spacy --gpu-id ${vars.gpu_id}"
    deps:
      - "data/${vars.dataset}_${vars.train}.spacy"
      - "data/${vars.dataset}_${vars.dev}.spacy"
    outputs:
      - "${vars.models.model_sbd}"

  - name: "evaluate_sbd"
    help: "Evaluate a trained SpanBoundaryDetection model"
    script:
      - "python -m spacy evaluate ${vars.models.model_sbd} data/${vars.dataset}_${vars.dev}.spacy --output metrics/sbd_${vars.dataset}_${vars.config}.json --gpu-id ${vars.gpu_id}"
    deps:
      - "data/${vars.dataset}_${vars.dev}.spacy"
      - "${vars.models.model_sbd}"
    outputs:
      - "metrics/sbd_${vars.dataset}_${vars.config}.json"

  - name: "train_spancat"
    help: "Train a spancat model"
    script:
      - "python -m spacy train configs/spancat/${vars.dataset}/${vars.config}_${vars.suggester}.cfg --output training/spancat/${vars.dataset}/${vars.config}_${vars.suggester}/ --paths.train data/${vars.dataset}_${vars.train}.spacy --paths.dev data/${vars.dataset}_${vars.dev}.spacy --paths.suggester_model ${vars.models.model_sbd} --gpu-id ${vars.gpu_id} --paths.span_key ${vars.span_key}"
    deps:
      - "data/${vars.dataset}_${vars.train}.spacy"
      - "data/${vars.dataset}_${vars.dev}.spacy"
    outputs:
      - "${vars.models.model_spancat}"

  - name: "evaluate_spancat"
    help: "Evaluate a  trained spancat model"
    script:
      - "python -m spacy evaluate ${vars.models.model_spancat} data/${vars.dataset}_${vars.dev}.spacy --output metrics/spancat_${vars.dataset}_${vars.config}_${vars.suggester}.json --gpu-id ${vars.gpu_id}"
    deps:
      - "${vars.models.model_spancat}"
    outputs:
      - metrics/spancat_${vars.dataset}_${vars.config}_${vars.suggester}.json

  - name: "evaluate_suggester"
    help: "Evaluate a the suggester of a trained spancat model"
    script:
      - "python scripts/evaluation.py ${vars.span_key} ${vars.models.model_spancat} data/${vars.dataset}_${vars.dev}.spacy"
    deps:
      - "${vars.models.model_spancat}"
      - "data/${vars.dataset}_${vars.dev}.spacy"

  - name: "reset"
    help: "Reset the project to its original state and delete all training process"
    script:
      - "python scripts/reset.py training"
      - "python scripts/reset.py metrics"
      - "python scripts/reset.py assets"
      - "python scripts/reset.py data"
